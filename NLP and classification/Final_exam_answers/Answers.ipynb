{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1f6442",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Practical MCQ: NLP and classification\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll explore and evaluate different machine learning classifiers through various tasks like model fitting, parameter tuning, and performance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "\n",
    "- Utilise vectorisation techniques to process textual data.\n",
    "- Implement logistic regression and measure its accuracy.\n",
    "- Determine optimal model parameters using grid search.\n",
    "- Interpret the output of machine learning models using confusion matrices.\n",
    "- Analyse the performance of classifiers with precision-recall metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c65d",
   "metadata": {},
   "source": [
    "> ⚠️ Please note that the multiple choices to all questions are not included in this notebook; they are available exclusively on the MCQ webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecec55",
   "metadata": {},
   "source": [
    "What does the `CountVectorizer` output `X` represent in the code snippet below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc759b03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 1 0 1 0 0]\n",
      " [1 1 1 0 0 1 1 1 1 1 1]]\n",
      "\n",
      "\n",
      "['and' 'are' 'closely' 'fascinating' 'is' 'language' 'learning' 'linked'\n",
      " 'machine' 'natural' 'processing']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "data = [\"Machine learning is fascinating.\", \"Natural language processing and machine learning are closely linked.\"]\n",
    "\n",
    "# Initialise the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(data)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "print(X.toarray())\n",
    "print(\"\\n\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccb80d",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Modify the code below to compute and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419ad301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9d0dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "# Accuracy: 0.958041958041958"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc9de7",
   "metadata": {},
   "source": [
    "What is the accuracy of the logistic regression model on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508e27",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the value of True Positive (TP) in the confusion matrix generated by the RandomForestClassifier below? Modify the code to print the value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bae0e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize and train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25577a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 113\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "TP = cm[1, 1]\n",
    "print(\"True Positive (TP):\", TP)\n",
    "# THE ANSWER \n",
    "#############\n",
    "# True Positive (TP): 113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93542c5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the best value of the parameter 'C' for the SVC according to the grid search? Modify the code to print the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b03d1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Load a dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Initialize an SVC (Support Vector Classifier) with a linear kernel\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Define parameter range for C (regularization parameter)\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "\n",
    "# Setup the grid search with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a41522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of the parameter 'C': 0.001\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "print(\"Best value of the parameter 'C':\", grid_search.best_params_['C'])\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "# Best value of the parameter 'C': 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98217731",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Which code snippet can be used to fill in the missing lines of code to train the SVM classifier, predict the test set results, and print the classification report?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ac91d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       115\n",
      "           1       0.89      0.81      0.85       135\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.84      0.85      0.84       250\n",
      "weighted avg       0.85      0.84      0.84       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier with a radial basis function kernel\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "# Fit the classifier to the training data\n",
    "# [Your Code Here] - Line to add for fitting the model\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "# [Your Code Here] - Line to add for making predictions\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "\n",
    "# Generate and print the classification report\n",
    "# [Your Code Here] - Line to add for printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e875cb9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Given the code below, your task is to select the function from the options provided that correctly completes the task by:\n",
    "\n",
    "i) Creating a function that determines which classifier (KNN or Naive Bayes) has a higher F1 score, or if they have equal scores.\n",
    "\n",
    "ii) Printing the name of the classifier along with its F1 score in the format: 'ClassifierName has the higher F1 score of Score' or 'Both classifiers have the same F1 score of Score'.\n",
    "\n",
    "iii) Executing the function.\n",
    "\n",
    "Select the appropriate code snippet from the options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a2bcc4-990a-4dd7-beef-6e7678d31e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THE ANSWER \n",
    "#############\n",
    "def compare_f1_scores(f1_knn, f1_nb):\n",
    "    if f1_knn > f1_nb:\n",
    "        print(\"KNN has the higher F1 score of\", f1_knn)\n",
    "    elif f1_nb > f1_knn:\n",
    "        print(\"Naive Bayes has the higher F1 score of\", f1_nb)\n",
    "    else:\n",
    "        print(\"Both classifiers have the same F1 score of\", f1_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6953839e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN has the higher F1 score of 0.8064516129032259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize KNN and Naive Bayes classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set results for both classifiers\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores for both classifiers\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "\n",
    "# [Your Code Here]\n",
    "# THE ANSWER \n",
    "#############\n",
    "compare_f1_scores(f1_knn, f1_nb)\n",
    "# KNN has the higher F1 score of 0.8064516129032259"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9667f9",
   "metadata": {},
   "source": [
    "## Question  7 \n",
    "\n",
    "Which of the following options will complete the missing code lines to:\n",
    "\n",
    "i) train the MLPClassifier, \n",
    "\n",
    "ii) predict the test set labels,\n",
    "\n",
    "iii) count the number of misclassified samples,\n",
    "\n",
    "iv) call the function to print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4c48cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified samples: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ALX_Training\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Generate a two-moon dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialise the MLPClassifier with one hidden layer with 10 neurons\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "\n",
    "# [Your Code Here] - Train the MLPClassifier on the scaled training data\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# [Your Code Here] - Predict the labels for the scaled test data\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# [Your Code Here] - Print the number of misclassified samples in the test set\n",
    "misclassified_samples = np.sum(y_test != y_pred)\n",
    "print(\"Number of misclassified samples:\", misclassified_samples)\n",
    "\n",
    "# Number of misclassified samples: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8065ab7",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Before running the final line of the code in the snippet below to fit the `grid_search` object, you are asked to perform the following tasks directly in the code:\n",
    "\n",
    "1. Modify the `param_grid` to include a new parameter: `'max_features'` with values ranging from 1 to 4.\n",
    "2. Fit the `grid_search` to the training data.\n",
    "3. After fitting, extract and print the best parameter combination and the corresponding cross-validation score.\n",
    "\n",
    "Which of the following options correctly completes these tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba25b24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combination: {'max_depth': None, 'max_features': 2, 'min_samples_split': 20}\n",
      "Corresponding cross-validation score: 0.9371541501976285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Setup a basic decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid over which to optimize the decision tree\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5)\n",
    "\n",
    "# THE ANSWER \n",
    "#############\n",
    "# Modify the param_grid to include a new parameter: 'max_features' with values ranging from 1 to 4\n",
    "param_grid['max_features'] = [1, 2, 3, 4]\n",
    "\n",
    "# Fit the grid_search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract and print the best parameter combination and the corresponding cross-validation score\n",
    "print(\"Best parameter combination:\", grid_search.best_params_)\n",
    "print(\"Corresponding cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b112d7e",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "You are fine-tuning a decision tree classifier for a marketing dataset. To prevent overfitting and ensure robust generalisability, you must adjust the depth of the decision tree after its initialisation but before it is fitted with data. Considering the decision tree `dt` has already been initialised with a random state, which of the following is the correct way to modify the tree's maximum depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38372bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialise decision tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# [Your Code Here]\n",
    "# Modify the maximum depth of the decision tree\n",
    "dt.set_params(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537192ee",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Suppose you are analysing the performance of a new email spam detection system using precision and recall. You have already computed these metrics, and you are about to explore their trade-offs to optimise the classifier's threshold. Given the code snippet below, identify the correct function call that would allow you to adjust and visualise the precision-recall trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b858357c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a RandomForest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_scores = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# [Your Code Here] - Generate precision and recall values for various thresholds\n",
    "# Generate precision and recall values for various thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198463ec",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are tasked with enhancing the robustness of a logistic regression model by incorporating feature scaling. You're currently working with a dataset that has significantly varying scales among its features, which can affect the model's performance. Below is a preliminary setup for the logistic regression model. Identify the correct sequence of steps to integrate feature scaling into the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd4e937",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# [Your Code Here] - Apply feature scaling to the training data\n",
    "# [Your Code Here] - Fit the model on the scaled training data\n",
    "# [Your Code Here] - Apply the same scaling to the test data\n",
    "\n",
    "# Apply feature scaling to the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Fit the model on the scaled training data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Apply the same scaling to the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9ab5e",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "\n",
    "You are fine-tuning a support vector machine (SVM) classifier to categorise images based on their content. The dataset consists of various animal images, and you suspect that different kernel functions might yield better classification accuracy. You decide to test which SVM kernel—linear or radial basis function (RBF)—works best for your specific dataset. Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc8d1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (Linear kernel): 0.9822222222222222\n",
      "Accuracy score (RBF kernel): 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset of digit images\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize two SVM classifiers, one with a linear kernel and another with an RBF kernel\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# [Your Code Here] - Train both classifiers on the training data\n",
    "# [Your Code Here] - Predict the test set results with both classifiers\n",
    "# [Your Code Here] - Calculate and print the accuracy scores for both classifiers\n",
    "\n",
    "# Train both classifiers on the training data\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results with both classifiers\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy scores for both classifiers\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "print(\"Accuracy score (Linear kernel):\", accuracy_linear)\n",
    "print(\"Accuracy score (RBF kernel):\", accuracy_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097f7ae",
   "metadata": {},
   "source": [
    "Which of the following options correctly completes the task of training both SVM classifiers, predicting the test set results, and calculating the accuracy for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f3dfa",
   "metadata": {},
   "source": [
    "## Question 13 \n",
    "\n",
    "You are currently evaluating two classifiers, K-Nearest Neighbours (KNN) and Naive Bayes, for a project that involves classifying texts into different categories based on their content. To finalise your model selection, you decide to visually compare their performance using a bar chart. Below is the setup for calculating the accuracy of both models on your dataset. Complete the code by adding the necessary lines to plot the accuracies in a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed671d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all')\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialise classifiers\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train classifiers\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn.predict(X_test_tfidf))\n",
    "nb_accuracy = accuracy_score(y_test, nb.predict(X_test_tfidf))\n",
    "\n",
    "# Plot the accuracies in a bar chart\n",
    "classifiers = ['K-Nearest Neighbours', 'Naive Bayes']\n",
    "accuracies = [knn_accuracy, nb_accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(classifiers, accuracies, color=['blue', 'green'])\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of KNN and Naive Bayes Classifiers')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8e77",
   "metadata": {},
   "source": [
    "Which snippet of code will correctly plot the accuracies of KNN and Naive Bayes classifiers in a bar chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db7298",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "You are tasked with evaluating a simple binary classification model using a confusion matrix. The dataset involves predicting whether a given email is spam or not. To better understand the model's performance, you plan to extract specific metrics from the confusion matrix, specifically True Positives (TP) and False Positives (FP). Below is your initial code setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a61dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 113\n",
      "False Positives (FP): 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic binary classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# [Your code here] - Extract and print True Positives and False Positives\n",
    "# Extract True Positives (TP) and False Positives (FP) from the confusion matrix\n",
    "TP = cm[1, 1]\n",
    "FP = cm[0, 1]\n",
    "\n",
    "# Print True Positives and False Positives\n",
    "print(\"True Positives (TP):\", TP)\n",
    "print(\"False Positives (FP):\", FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf3d05",
   "metadata": {},
   "source": [
    "Which snippet of code correctly extracts and prints the True Positives (TP) and False Positives (FP) from the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54632b17",
   "metadata": {},
   "source": [
    "Which snippet of code correctly completes the setup to create a pipeline including `PolynomialFeatures` and `LogisticRegression`, fits it on the training data, and makes predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e805e0e7-c682-40e4-971c-80f467f97364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a pipeline including PolynomialFeatures and LogisticRegression\n",
    "pipeline = make_pipeline(PolynomialFeatures(), LogisticRegression())\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3781c44",
   "metadata": {},
   "source": [
    "## Question 15 (Medium)\n",
    "\n",
    "You are refining a logistic regression model to predict customer churn. The dataset includes various customer interaction metrics. To enhance your model, explore how polynomial features can improve prediction accuracy. This approach allows the model to capture complex interactions between variables. \n",
    "\n",
    "Here is your setup: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08305212",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of informative, redundant and repeated features must sum to less than the number of total features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate synthetic data for binary classification\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m make_classification(n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ALX_Training\\Lib\\site-packages\\sklearn\\datasets\\_samples_generator.py:178\u001b[0m, in \u001b[0;36mmake_classification\u001b[1;34m(n_samples, n_features, n_informative, n_redundant, n_repeated, n_classes, n_clusters_per_class, weights, flip_y, class_sep, hypercube, shift, scale, shuffle, random_state)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Count features, clusters and samples\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m+\u001b[39m n_redundant \u001b[38;5;241m+\u001b[39m n_repeated \u001b[38;5;241m>\u001b[39m n_features:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of informative, redundant and repeated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures must sum to less than the number of total\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Use log2 to avoid overflow errors\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_informative \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(n_classes \u001b[38;5;241m*\u001b[39m n_clusters_per_class):\n",
      "\u001b[1;31mValueError\u001b[0m: Number of informative, redundant and repeated features must sum to less than the number of total features"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate synthetic data for binary classification\n",
    "X, y = make_classification(n_samples=1000, n_features=3, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Apply polynomial features manually\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on polynomial features\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2e94",
   "metadata": {},
   "source": [
    "What is the correct procedure to fit a logistic regression model on the training data after transforming it with polynomial features, and how should predictions be made on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92589bc-2146-4177-8ed9-f7f46e1ae5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on polynomial features\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
