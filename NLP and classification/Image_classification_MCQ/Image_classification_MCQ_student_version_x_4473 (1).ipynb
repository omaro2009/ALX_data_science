{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZz-A8wJhg0M"
      },
      "source": [
        "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
        "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02VBjK6khg0O"
      },
      "source": [
        "\n",
        "## Image classification MCQ\n",
        "Â© ExploreAI Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuV4iz15hg0P"
      },
      "source": [
        "The versatile machine learning techniques you have been learning will enable you to process complex and different data at a faster pace.  \n",
        "\n",
        "So far you have performed classification on both tabular  ([iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)) and textual data ([the mbti dataset](https://www.kaggle.com/datasnaek/mbti-type)). In this notebook, you will apply the machine learning techniques you have learned for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlTT2Wfqhg0Q"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Let's go ahead and load our libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d3asnGgGhg0R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gzip # This is used in extracting the images\n",
        "\n",
        "import matplotlib.pyplot as plt # In order to plot the images to see what we are dealing with\n",
        "from sklearn.ensemble import RandomForestClassifier # You'll be using Random Forest to classify the images\n",
        "from sklearn.metrics import accuracy_score # Sklearn's way of measuring accuracy\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ew6QB8Ghg0S"
      },
      "source": [
        "\n",
        "# The data\n",
        "\n",
        "The dataset we will be using is called `MNIST`. This is a large collection of hand-drawn digits `0 to 9` and is a good dataset to learn image classification on as it requires little to no preprocessing.\n",
        "\n",
        "The dataset can be downloaded from [The MNIST Database](https://web.archive.org/web/20220331130319/https://yann.lecun.com/exdb/mnist/). Download all four files. These files are the images and their respective labels (normally, we're required to split the x (image data / characteristics) and y (labels) out during preprocessing, but this has already been done for us). The dataset has also already been split into a train and a test set.\n",
        "\n",
        "Once you've downloaded the data, make sure that the data are in the same folder as this Jupyter notebook. If you've managed to do all that, we can now begin!\n",
        "\n",
        "By default, the MNIST files are compressed in the gzip format. The following two functions will extract the data for you. ** **Don't change this code.** **"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pKKKJC9LiZxL",
        "outputId": "66a65aca-44ac-48b6-e49a-dcc70354dfe3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70df2b4d-6838-4e57-879f-810898773657\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70df2b4d-6838-4e57-879f-810898773657\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train-labels-idx1-ubyte.gz to train-labels-idx1-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3lbVap-Xhg0T"
      },
      "outputs": [],
      "source": [
        "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
        "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\"\"\"\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        bytestream.read(16)\n",
        "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
        "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
        "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
        "        return data\n",
        "\n",
        "def extract_labels(filename, num_images):\n",
        "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
        "    with gzip.open(filename) as bytestream:\n",
        "        bytestream.read(8)\n",
        "        buf = bytestream.read(1 * num_images)\n",
        "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLtbU1gYhg0U"
      },
      "source": [
        "## Challenge 1: Extracting the data\n",
        "\n",
        "The MNIST dataset consists of 60,000 training images and 10,000 testing images. This is a lot of data! Let's not extract all of that right now. Create a function `get_data` that uses the above functions to extract a certain number of images and their labels from the gzip files.\n",
        "\n",
        "The function will take as input two integer values, the number of train and test images to be extracted. Let's extract `5000` train images and `1000` test images. The function then returns four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the extracted images and labels of the training set, and `(X-test, y_test)` are the extracted images and labels of the testing set. (Hint â you'll have to use the functions provided more than once.)\n",
        "\n",
        "Image pixel values range from 0 to 255. We need to normalise the image pixels so that they are in the range 0 to 1.\n",
        "\n",
        "_**Function specifications:**_\n",
        "* Should take two integers as input, one representing the number of training images and the other the number of testing images.\n",
        "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
        "\n",
        "_**Note**_ that the size of the MNIST images is 28x28.\n",
        "\n",
        "Usually when setting up your dataset, it is a good idea to randomly shuffle your data in case your data are ordered. Think of this as shuffling a pack of cards. Here, however, we aren't going to shuffle the data so that all our answers are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A9LXb-rhg0U",
        "outputId": "9f9c4f84-91c3-4dfa-ec73-457756b539c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10980392\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "### START FUNCTION\n",
        "train_images_file='train-images-idx3-ubyte.gz'\n",
        "train_labels_file='train-labels-idx1-ubyte.gz'\n",
        "test_images_file='t10k-images-idx3-ubyte.gz'\n",
        "test_labels_file='t10k-labels-idx1-ubyte.gz'\n",
        "def get_data(num_train_images,num_test_images):\n",
        "    #your code here\n",
        "    IMAGE_WIDTH = 28\n",
        "    NUM_TRAIN_IMAGES = 5000\n",
        "    NUM_TEST_IMAGES = 1000\n",
        "\n",
        "    X_train = extract_data(train_images_file, NUM_TRAIN_IMAGES, IMAGE_WIDTH)\n",
        "    y_train = extract_labels(train_labels_file, NUM_TRAIN_IMAGES)\n",
        "    X_test = extract_data(test_images_file, NUM_TEST_IMAGES, IMAGE_WIDTH)\n",
        "    y_test = extract_labels(test_labels_file, NUM_TEST_IMAGES)\n",
        "\n",
        "    #your code here\n",
        "    X_train /= 255.0\n",
        "    X_test /= 255.0\n",
        "    # Select the specified number of images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "### END FUNCTION\n",
        "(X_train, y_train), (X_test, y_test) = get_data(5000, 1000)\n",
        "print( X_train[1, 349])\n",
        "print( y_test[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJiHkcWqhg0V"
      },
      "source": [
        "## Plotting the data\n",
        "\n",
        "Let's see what this data looks like! Right now the images are \"flattened\" into a 1-D array of length 784. In order to plot the image we first need to reshape it to the correct size of 28x28. We'll print out the respective label to make sure we are plotting the right number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "1O6WLhS2hg0V",
        "outputId": "e7fca1d4-e0c8-4723-b04c-2f1677049d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "image_index = 3 ## Change me to view different images\n",
        "\n",
        "print(\"Label: \", y_train[image_index])\n",
        "reshaped_image = X_train[image_index].reshape((28, 28))\n",
        "\n",
        "plt.imshow(reshaped_image, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hJhG8bXhg0W"
      },
      "source": [
        "## Challenge 2: Training the model\n",
        "\n",
        "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestClassifier` class with `20 estimators` and its `random_state` set to `42`. We'll write a function that will take as input the image and label variables that we created previously, and return a trained model.\n",
        "\n",
        "_**Function specifications:**_\n",
        "* Should take two NumPy `arrays` as input in the form `(X_train, y_train)`.\n",
        "* Should return an sklearn `RandomForestClassifier` model which has a random state of 42 and number of estimators 20.\n",
        "* The returned model should be fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qBK16ijrhg0X"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "def train_model(X_train, y_train):\n",
        "    model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t_SZWj3jhg0X"
      },
      "outputs": [],
      "source": [
        "clf = train_model(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDxdOcQhg0Y"
      },
      "source": [
        "## Challenge 3: Testing the model\n",
        "\n",
        "Now that you have trained your model, let's see how well it does on the test set. Write a function which returns the accuracy of our trained model when tested with the test set.\n",
        "\n",
        "_**Function specifications:**_\n",
        "* Should take the fitted model `clf` and two NumPy arrays `X_test, y_test` as input.\n",
        "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LfdB8XZvhg0Y"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "def calculate_accuracy(clf, X_test, y_test):\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the model\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "def calculate_precision_for_label(clf, X_test, y_test, label):\n",
        "    # Use the trained model to predict labels for the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Calculate precision for the specified label\n",
        "    precision = precision_score(y_test, y_pred, average=None)[label]\n",
        "    return precision\n",
        "precision_6 = calculate_precision_for_label(clf, X_test, y_test, label=6)\n",
        "print(\"Precision for label 6:\", precision_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ez2xb1k3vRw",
        "outputId": "32171f16-0922-4753-ea8b-e32acb6d2af5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for label 6: 0.9101123595505618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1_score_for_label(clf, X_test, y_test, label):\n",
        "    # Use the trained model to predict labels for the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Calculate F1-score for the specified label\n",
        "    f1_score_value = f1_score(y_test, y_pred, average=None)[label]\n",
        "    return f1_score_value\n",
        "f1_score_0 = calculate_f1_score_for_label(clf, X_test, y_test, label=0)\n",
        "print(\"F1-score for label 0:\", f1_score_0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff6nYfs54nmO",
        "outputId": "1448f7c1-4f61-418d-8ef0-3b61ce1bb6b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score for label 0: 0.9655172413793103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc0j-4JRhg0Y",
        "outputId": "307f6f19-a422-491d-9d14-02563bf4ce09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.891\n"
          ]
        }
      ],
      "source": [
        "print(calculate_accuracy(clf,X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik-I19OMhg0Z"
      },
      "source": [
        "Classification reports give us more information on where our model is going wrong â looking specifically at the performance caused by Type I and II errors. Write a function that returns the classification report of your test set.\n",
        "\n",
        "_**Function specifications:**_\n",
        "* Should take the fitted model `clf` and two NumPy arrays `X_test, y_test` as input.\n",
        "* Should return a classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YiSRTLVFhg0Z"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "def get_class_report(clf, X_test, y_test):\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Generate the classification report\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    return report\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_NxWo0bhg0Z",
        "outputId": "535fadb1-5d5e-43c4-a1b3-81aa8ec73047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97        85\n",
            "           1       0.98      0.98      0.98       126\n",
            "           2       0.88      0.90      0.89       116\n",
            "           3       0.84      0.83      0.84       107\n",
            "           4       0.86      0.90      0.88       110\n",
            "           5       0.86      0.85      0.86        87\n",
            "           6       0.91      0.93      0.92        87\n",
            "           7       0.88      0.85      0.87        99\n",
            "           8       0.93      0.78      0.85        89\n",
            "           9       0.81      0.88      0.85        94\n",
            "\n",
            "    accuracy                           0.89      1000\n",
            "   macro avg       0.89      0.89      0.89      1000\n",
            "weighted avg       0.89      0.89      0.89      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(get_class_report(clf,X_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-NQFZnhg0a"
      },
      "source": [
        "## Plotting the results\n",
        "\n",
        "Let's actually see if our model has trained correctly. To do so, plot some of the images with their predicted labels. Since we don't have the predictions stored in our notebook's memory, we need to call the predict function here first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "HkOpPxothg0a",
        "outputId": "3b14660e-6316-4e1b-a728-ec885feb3a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label:  7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "preds = clf.predict(X_test)\n",
        "\n",
        "image_index = 60 ## Change me to see other predictions\n",
        "\n",
        "print(\"Predicted Label: \",preds[image_index])\n",
        "plt.imshow(X_test[image_index].reshape((28, 28)), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question1\n",
        "X_train_shape = X_train.shape\n",
        "X_test_shape = X_test.shape\n",
        "\n",
        "print(\"Shape of X_train:\", X_train_shape)\n",
        "print(\"Shape of X_test:\", X_test_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf0Ye7vFzDTe",
        "outputId": "fc8ef167-4b60-4d8b-c2ef-2d112b846de7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (5000, 784)\n",
            "Shape of X_test: (1000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoDCQbkshg0a"
      },
      "source": [
        "Since we didn't use all the data in the beginning, there is a chance our performance can improve. Go change the amount of data we use to see how it affects the accuracy of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oePQd3_Mhg0a"
      },
      "source": [
        "#  \n",
        "\n",
        "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
        "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}